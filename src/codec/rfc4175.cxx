/*
 * rfc4175.cxx
 *
 * RFC4175 transport for uncompressed video
 *
 * Open Phone Abstraction Library
 *
 * Copyright (C) 2007 Post Increment
 *
 * The contents of this file are subject to the Mozilla Public License
 * Version 1.0 (the "License"); you may not use this file except in
 * compliance with the License. You may obtain a copy of the License at
 * http://www.mozilla.org/MPL/
 *
 * Software distributed under the License is distributed on an "AS IS"
 * basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See
 * the License for the specific language governing rights and limitations
 * under the License.
 *
 * The Original Code is Open Phone Abstraction Library.
 *
 * The Initial Developer of the Original Code is Post Increment
 *
 * Contributor(s): ______________________________________.
 *
 * $Revision$
 * $Author$
 * $Date$
 */

#include <ptlib.h>

#ifdef __GNUC__
#pragma implementation "rfc4175.h"
#endif

#include <opal/buildopts.h>

#if OPAL_RFC4175

#include <ptclib/random.h>
#include <opal/mediafmt.h>
#include <codec/rfc4175.h>
#include <codec/opalplugin.h>

namespace PWLibStupidLinkerHacks {
  int rfc4175Loader;
};

#define   FRAME_WIDTH   1920
#define   FRAME_HEIGHT  1080
#define   FRAME_RATE    60

#define   REASONABLE_UDP_PACKET_SIZE  800

class RFC4175VideoFormat : public OpalVideoFormat
{
  PCLASSINFO(RFC4175VideoFormat, OpalVideoFormat);
  public:
    RFC4175VideoFormat(
      const char * fullName,    ///<  Full name of media format
      const char * samplingName,
      unsigned int bandwidth
    );
};

const OpalVideoFormat & GetOpalRFC4175_YCbCr420()
{
  static const RFC4175VideoFormat RFC4175_YCbCr420(OPAL_RFC4175_YCbCr420, "YCbCr-4:2:0", (FRAME_WIDTH*FRAME_HEIGHT*3/2)*FRAME_RATE);
  return RFC4175_YCbCr420;
}

OPAL_REGISTER_RFC4175_VIDEO(YUV420P, YCbCr420)

const OpalVideoFormat & GetOpalRFC4175_RGB()
{
  static const RFC4175VideoFormat RFC4175_RGB(OPAL_RFC4175_RGB, "RGB", FRAME_WIDTH*FRAME_HEIGHT*3*FRAME_RATE);
  return RFC4175_RGB;
}

OPAL_REGISTER_RFC4175_VIDEO(RGB24, RGB)

/////////////////////////////////////////////////////////////////////////////

RFC4175VideoFormat::RFC4175VideoFormat(
      const char * fullName,    ///<  Full name of media format
      const char * samplingName,
      unsigned int bandwidth)
 : OpalVideoFormat(fullName, 
                   RTP_DataFrame::DynamicBase,
                   "raw",
                   FRAME_WIDTH, FRAME_HEIGHT,
                   FRAME_RATE,
                   bandwidth)
{
  OpalMediaOption * option;

  // add mandatory fields
  option = FindOption(ClockRateOption());
  if (option != NULL)
    option->SetFMTPName("rate");

  option = new OpalMediaOptionString("rfc4175_sampling", TRUE, samplingName);
  option->SetFMTPName("sampling");
  AddOption(option, TRUE);

  option = FindOption(FrameWidthOption());
  if (option != NULL)
    option->SetFMTPName("width");

  option = FindOption(FrameHeightOption());
  if (option != NULL)
    option->SetFMTPName("height");

  option = new OpalMediaOptionInteger("rfc4175_depth", TRUE, OpalMediaOption::NoMerge, 8);
  option->SetFMTPName("depth");
  AddOption(option, TRUE);

  option = new OpalMediaOptionString("rfc4175_colorimetry", TRUE, "BT601-5");
  option->SetFMTPName("colorimetry");
  AddOption(option, TRUE);
}

/////////////////////////////////////////////////////////////////////////////

OpalRFC4175Transcoder::OpalRFC4175Transcoder(      
      const OpalMediaFormat & inputMediaFormat,  ///<  Input media format
      const OpalMediaFormat & outputMediaFormat  ///<  Output media format
)
 : OpalVideoTranscoder(inputMediaFormat, outputMediaFormat)
{
}

PINDEX OpalRFC4175Transcoder::RFC4175HeaderSize(PINDEX lines)
{ return 2 + lines*6; }

/////////////////////////////////////////////////////////////////////////////

OpalRFC4175Encoder::OpalRFC4175Encoder(      
  const OpalMediaFormat & inputMediaFormat,  ///<  Input media format
  const OpalMediaFormat & outputMediaFormat  ///<  Output media format
) : OpalRFC4175Transcoder(inputMediaFormat, outputMediaFormat)
{
#ifdef _DEBUG
  extendedSequenceNumber = 0;
#else
  extendedSequenceNumber = PRandom::Number();
#endif

  maximumPacketSize      = REASONABLE_UDP_PACKET_SIZE;
}

void OpalRFC4175Encoder::StartEncoding(const RTP_DataFrame &)
{
}

BOOL OpalRFC4175Encoder::ConvertFrames(const RTP_DataFrame & input, RTP_DataFrameList & _outputFrames)
{
  _outputFrames.RemoveAll();

  PAssert(sizeof(ScanLineHeader) == 6, "ScanLineHeader is not packed");

  // make sure the incoming frame is big enough for a frame header
  if (input.GetPayloadSize() < (int)(sizeof(PluginCodec_Video_FrameHeader))) {
    PTRACE(1,"RFC4175\tPayload of grabbed frame too small for frame header");
    return FALSE;
  }

  PluginCodec_Video_FrameHeader * header = (PluginCodec_Video_FrameHeader *)input.GetPayloadPtr();
  if (header->x != 0 && header->y != 0) {
    PTRACE(1,"RFC4175\tVideo grab of partial frame unsupported");
    return FALSE;
  }

  // get information from frame header
  frameHeight       = header->height;
  frameWidth        = header->width;

  // make sure the incoming frame is big enough for the specified frame size
  if (input.GetPayloadSize() < (int)(sizeof(PluginCodec_Video_FrameHeader) + PixelsToBytes(frameWidth*frameHeight))) {
    PTRACE(1,"RFC4175\tPayload of grabbed frame too small for full frame");
    return FALSE;
  }

  srcTimestamp = input.GetTimestamp();

  StartEncoding(input);

  // save pointer to output data
  dstFrames = &_outputFrames;
  dstScanlineCounts.resize(0);

  // encode the full frame
  EncodeFullFrame();

  // grab the actual data
  EndEncoding();

  return TRUE;
}

void OpalRFC4175Encoder::EncodeFullFrame()
{
  // encode the scan lines
  unsigned y;
  for (y = 0; y < frameHeight; y += GetRowsPerPgroup())
    EncodeScanLineSegment(y, 0, frameWidth);
}

void OpalRFC4175Encoder::EncodeScanLineSegment(PINDEX y, PINDEX offs, PINDEX width)
{
  // add new packets until scan line segment is finished
  PINDEX endX = offs + width;
  PINDEX x = offs;
  while (x < endX) {

    PINDEX roomLeft = maximumPacketSize - dstPacketSize;

    // if current frame cannot hold at least one pgroup, then add a new frame
    if ((dstFrames->GetSize() == 0) || (roomLeft < (PINDEX)(sizeof(ScanLineHeader) + GetPgroupSize()))) {
      AddNewDstFrame();
      continue;
    }

    // calculate how many pixels we can add
    PINDEX pixelsToAdd = PMIN((roomLeft - (PINDEX)sizeof(ScanLineHeader)) / GetPgroupSize(), endX - x);

    PAssert(pixelsToAdd > 0, "how did we get negative pixels?");

    // populate the scan line table
    dstScanLineTable->length = (WORD)pixelsToAdd;
    dstScanLineTable->y      = (WORD)y;
    dstScanLineTable->offset = (WORD)x;

    // adjust pointer to scan line table and number of scan lines
    ++dstScanLineTable;
    ++dstScanLineCount;

    // adjust packet size
    dstPacketSize += sizeof(ScanLineHeader) + (pixelsToAdd * GetPgroupSize());

    // adjust X offset
    x += pixelsToAdd;
  }
}

void OpalRFC4175Encoder::AddNewDstFrame()
{
  // complete the previous output frame (if any)
  FinishOutputFrame();

  // allocate a new output frame
  RTP_DataFrame * frame = new RTP_DataFrame;
  dstFrames->Append(frame);

  // initialise payload size for maximum size
  frame->SetPayloadSize(maximumPacketSize - frame->GetHeaderSize());

  // initialise current output scanline count;
  dstScanLineCount = 0;
  dstPacketSize    = frame->GetHeaderSize();
  dstScanLineTable = (ScanLineHeader *)(frame->GetPayloadPtr() + 2);
}

void OpalRFC4175Encoder::FinishOutputFrame()
{
  if ((dstFrames->GetSize() > 0) && (dstScanLineCount > 0)) {

    // populate the frame fields
    RTP_DataFrame & dst = (*dstFrames)[dstFrames->GetSize()-1];

    // set the end of scan line table bit
    --dstScanLineTable;
    dstScanLineTable->offset = (WORD)dstScanLineTable->offset | 0x8000;

    // set the timestamp and payload type
    dst.SetTimestamp(srcTimestamp);
    dst.SetPayloadType(outputMediaFormat.GetPayloadType());

    // set and increment the sequence number
    dst.SetSequenceNumber((WORD)(extendedSequenceNumber & 0xffff));
    *(PUInt16b *)dst.GetPayloadPtr() = (WORD)((extendedSequenceNumber >> 16) & 0xffff);
    ++extendedSequenceNumber;

    // set actual payload size
    dst.SetPayloadSize(dstPacketSize - dst.GetHeaderSize());

    // save scanline count
    dstScanlineCounts.push_back(dstScanLineCount);
  }
}

/////////////////////////////////////////////////////////////////////////////

OpalRFC4175Decoder::OpalRFC4175Decoder(      
  const OpalMediaFormat & inputMediaFormat,  ///<  Input media format
  const OpalMediaFormat & outputMediaFormat  ///<  Output media format
) : OpalRFC4175Transcoder(inputMediaFormat, outputMediaFormat)
{
  inputFrames.AllowDeleteObjects();
  first = TRUE;
  waitingForMarker = FALSE;
  Initialise();
}

OpalRFC4175Decoder::~OpalRFC4175Decoder()
{
}

BOOL OpalRFC4175Decoder::Initialise()
{
  frameWidth  = 0;
  frameHeight = 0;

  inputFrames.RemoveAll();
  scanlineCounts.resize(0);

  packetCount = 0;

  return TRUE;
}

BOOL OpalRFC4175Decoder::ConvertFrames(const RTP_DataFrame & input, RTP_DataFrameList & output)
{
  output.RemoveAll();

  PAssert(sizeof(ScanLineHeader) == 6, "ScanLineHeader is not packed");

  // do quick sanity check on packet
  if (input.GetPayloadSize() < 2) {
    PTRACE(1,"RFC4175\tinput frame too small for header");
    return FALSE;
  }

  // get extended sequence number
  DWORD receivedSeqNo = input.GetSequenceNumber() | ((*(PUInt16b *)input.GetPayloadPtr()) << 16);

  // special handling for first packet
  if (first) {
    lastSequenceNumber = receivedSeqNo;
    lastTimeStamp      = input.GetTimestamp();
    first = FALSE;
  } 

  // if waiting for a marker bit to resync, keep waiting
  else if (waitingForMarker) {
    if (!input.GetMarker()) {
      PTRACE(1,"RFC4175\tignoring frame while waiting for marker bit");
    } else {
      PTRACE(1,"RFC4175\tmarker bit received - starting new frame");
      first = TRUE;
      lastTimeStamp      = input.GetTimestamp();
      lastSequenceNumber = receivedSeqNo;
    }
    return TRUE;
  }

  else if (!input.GetMarker() && (inputFrames.GetSize() > 0)) {
    // if timestamp changed, marker bit lost on previous input frame
    DWORD timeStamp = input.GetTimestamp();
    if (timeStamp != lastTimeStamp) {
      PTRACE(2, "RFC4175\tDetected change of timestamp (" << lastTimeStamp << " vs " << timeStamp << ") after " << packetCount << " packets - discarding frame");
      lastSequenceNumber = receivedSeqNo;
      lastTimeStamp      = timeStamp;
      Initialise();
    }

    // if sequence number is not sequential, then frame is not complete
    else {
      ++lastSequenceNumber;
      if (lastSequenceNumber != receivedSeqNo) {
        PTRACE(2, "RFC4175\tDetected lost frame after " << packetCount << " packets - flushing until next marker bit");
        Initialise();
        waitingForMarker = TRUE;
        return TRUE;
      }
    }
  }

  ++packetCount;

  // make a pass through the scan line table and update the overall frame width and height
  PINDEX lineCount = 0;

  ScanLineHeader * scanLinePtr = (ScanLineHeader *)(input.GetPayloadPtr() + 2);

  BOOL lastLine = FALSE;
  while (!lastLine && RFC4175HeaderSize(lineCount+1) < input.GetPayloadSize()) {

    // scan line length
    PINDEX lineLength = scanLinePtr->length;

    // line number 
    WORD lineNumber = scanLinePtr->y & 0x7fff; 

    // pixel offset of scanline start
    WORD offset = scanLinePtr->offset;

    // detect if last scanline in table
    if (offset & 0x8000) {
      lastLine = TRUE;
      offset &= 0x7fff;
    }

    // update frame width and height
    PINDEX right = offset + lineLength;
    if (right > frameWidth)
      frameWidth = right;
    PINDEX bottom = lineNumber+2;
    if (bottom > frameHeight)
      frameHeight = bottom;

    // count lines
    ++lineCount;

    // update scan line pointer
    ++scanLinePtr;
  }

  // add the frame to the input frame list
  inputFrames.Append(input.Clone());
  scanlineCounts.push_back(lineCount);

  // if marker set, decode the frames
  if (input.GetMarker()) 
    DecodeFrames(output);

  return TRUE;
}

/////////////////////////////////////////////////////////////////////////////

void Opal_YUV420P_to_RFC4175YCbCr420::StartEncoding(const RTP_DataFrame & input)
{
  // save pointers to input data
  srcYPlane    = input.GetPayloadPtr() + sizeof(PluginCodec_Video_FrameHeader);
  srcCbPlane   = srcYPlane  + (frameWidth * frameHeight);
  srcCrPlane   = srcCbPlane + (frameWidth * frameHeight / 4);
}

void Opal_YUV420P_to_RFC4175YCbCr420::EndEncoding()
{
  FinishOutputFrame();

  PTRACE(4, "RFC4175\tEncoded YUV420P input frame to " << dstFrames->GetSize() << " RFC4175 output frames in YCbCr420 format");

  PINDEX f, i;
  for (f = 0; f < dstFrames->GetSize(); ++f) {
    RTP_DataFrame & output = (*dstFrames)[f];
    ScanLineHeader * hdrs = (ScanLineHeader *)(output.GetPayloadPtr() + 2);
    BYTE * scanLineDataPtr = output.GetPayloadPtr() + 2 + dstScanlineCounts[f] * sizeof (ScanLineHeader);
    for (i = 0; i < dstScanlineCounts[f]; ++i) {
      ScanLineHeader & hdr = hdrs[i];

      PINDEX x     = hdr.offset & 0x7fff;
      PINDEX y     = hdr.y & 0x7fff;
      unsigned len = hdr.length;

      BYTE * yPlane0  = srcYPlane  + (frameWidth * y + x);
      BYTE * yPlane1  = yPlane0    + frameWidth;
      BYTE * cbPlane  = srcCbPlane + (frameWidth * y / 4) + x / 2;
      BYTE * crPlane  = srcCrPlane + (frameWidth * y / 4) + x / 2;

      unsigned p;
      for (p = 0; p < len; p += 2) {
        *scanLineDataPtr++ = *yPlane0++;
        *scanLineDataPtr++ = *yPlane0++;
        *scanLineDataPtr++ = *yPlane1++;
        *scanLineDataPtr++ = *yPlane1++;
        *scanLineDataPtr++ = *cbPlane++;
        *scanLineDataPtr++ = *crPlane++;
      }
    }
  } 

  // set marker bit on last frame
  if (dstFrames->GetSize() != 0) {
    RTP_DataFrame & dst = (*dstFrames)[dstFrames->GetSize()-1];
    dst.SetMarker(TRUE);
  }
}

/////////////////////////////////////////////////////////////////////////////

BOOL Opal_RFC4175YCbCr420_to_YUV420P::DecodeFrames(RTP_DataFrameList & output)
{
  if (inputFrames.GetSize() == 0) {
    PTRACE(4, "RFC4175\tNo input frames to decode");
    return FALSE;
  }

  //if (frameHeight != 144 || frameWidth != 176) {
  //  int s = inputFrames.GetSize();
  //  PTRACE(4, "not right frame " << s);
  //}

  PTRACE(4, "RFC4175\tDecoding output from " << inputFrames.GetSize() << " input frames");

  // allocate destination frame
  output.Append(new RTP_DataFrame());
  RTP_DataFrame & outputFrame = output[output.GetSize()-1];
  outputFrame.SetMarker(TRUE);
  outputFrame.SetPayloadType(outputMediaFormat.GetPayloadType());
  outputFrame.SetPayloadSize(sizeof(PluginCodec_Video_FrameHeader) + PixelsToBytes(frameWidth*frameHeight));

  // get pointer to header and payload
  PluginCodec_Video_FrameHeader * hdr = (PluginCodec_Video_FrameHeader *)outputFrame.GetPayloadPtr();
  hdr->x = 0;
  hdr->y = 0;
  hdr->width  = frameWidth;
  hdr->height = frameHeight;

  BYTE * payload    = OPAL_VIDEO_FRAME_DATA_PTR(hdr);
  BYTE * dstYPlane  = payload;
  BYTE * dstCbPlane = dstYPlane  + (frameWidth * frameHeight);
  BYTE * dstCrPlane = dstCbPlane + (frameWidth * frameHeight / 4);

  // pass through all of the input frames, and extract information
  PINDEX f;
  for (f = 0; f < inputFrames.GetSize(); ++f) {

    RTP_DataFrame & source = inputFrames[f];

    // scan through table
    PINDEX l;
    ScanLineHeader * tablePtr = (ScanLineHeader *)(source.GetPayloadPtr() + 2);

    BYTE * yuvData = source.GetPayloadPtr() + 2 + scanlineCounts[f] * sizeof(ScanLineHeader);

    for (l = 0; l < scanlineCounts[f]; ++l) {

      // scan line length
      PINDEX width = tablePtr->length;

      // line number 
      WORD y = tablePtr->y & 0x7fff; 

      // pixel offset of scanline start
      WORD x = tablePtr->offset & 0x7fff;

      ++tablePtr;

      // only convert lines on even boundaries
      if (
          ((y & 1) == 0) 
          ) {

        BYTE * yPlane0 = dstYPlane  + y * frameWidth + x;
        BYTE * yPlane1 = yPlane0    + frameWidth;
        BYTE * cbPlane = dstCbPlane + (y * frameWidth / 4) + x / 2;
        BYTE * crPlane = dstCrPlane + (y * frameWidth / 4) + x / 2;

        PINDEX i;
        for (i = 0; i < width; i += 2) {
          *yPlane0++ = *yuvData++;
          *yPlane0++ = *yuvData++;
          *yPlane1++ = *yuvData++;
          *yPlane1++ = *yuvData++;
          *cbPlane++ = *yuvData++;
          *crPlane++ = *yuvData++;
        }
      }
    }
  }

  // reinitialise the buffers
  Initialise();

  return TRUE;
}

/////////////////////////////////////////////////////////////////////////////

void Opal_RGB24_to_RFC4175RGB::StartEncoding(const RTP_DataFrame & input)
{
  // save pointer to input data
  rgbBase  = input.GetPayloadPtr() + sizeof(PluginCodec_Video_FrameHeader);
}

void Opal_RGB24_to_RFC4175RGB::EndEncoding()
{
  FinishOutputFrame();

  PTRACE(4, "RFC4175\tEncoded RGB24 input frame to " << (dstFrames->GetSize()) << " RFC4175 output frames in RGB format");

  PINDEX f, i;
  for (f = 0; f < dstFrames->GetSize(); ++f) {
    RTP_DataFrame & output = (*dstFrames)[f];
    ScanLineHeader * hdrs = (ScanLineHeader *)(output.GetPayloadPtr() + 2);
    BYTE * scanLineDataPtr = output.GetPayloadPtr() + 2 + dstScanlineCounts[f] * sizeof (ScanLineHeader);
    for (i = 0; i < dstScanlineCounts[f]; ++i) {
      ScanLineHeader & hdr = hdrs[i];

      PINDEX x     = hdr.offset & 0x7fff;
      PINDEX y     = hdr.y & 0x7fff;
      unsigned len = hdr.length;

      memcpy(scanLineDataPtr, rgbBase + (y * frameWidth + x) * 3, len * 3); 

      scanLineDataPtr += len * 3;
    }
  } 

  // set marker bit on last frame
  if (dstFrames->GetSize() != 0) {
    RTP_DataFrame & dst = (*dstFrames)[dstFrames->GetSize()-1];
    dst.SetMarker(TRUE);
  }
}

/////////////////////////////////////////////////////////////////////////////

BOOL Opal_RFC4175RGB_to_RGB24::DecodeFrames(RTP_DataFrameList & output)
{
  if (inputFrames.GetSize() == 0) {
    PTRACE(4, "RFC4175\tNo input frames to decode");
    return FALSE;
  }

  PTRACE(4, "RFC4175\tDecoding output from " << inputFrames.GetSize() << " input frames");

  // allocate destination frame
  output.Append(new RTP_DataFrame());
  RTP_DataFrame & outputFrame = output[output.GetSize()-1];
  outputFrame.SetMarker(TRUE);
  outputFrame.SetPayloadSize(sizeof(PluginCodec_Video_FrameHeader) + PixelsToBytes(frameWidth*frameHeight));

  // get pointer to header and payload
  PluginCodec_Video_FrameHeader * hdr = (PluginCodec_Video_FrameHeader *)outputFrame.GetPayloadPtr();
  hdr->x = 0;
  hdr->y = 0;
  hdr->width  = frameWidth;
  hdr->height = frameHeight;

  BYTE * rgbDest = OPAL_VIDEO_FRAME_DATA_PTR(hdr);

  // pass through all of the input frames, and extract information
  PINDEX f;
  for (f = 0; f < inputFrames.GetSize(); ++f) {

    RTP_DataFrame & source = inputFrames[f];

    // scan through table
    PINDEX l;
    ScanLineHeader * tablePtr = (ScanLineHeader *)(source.GetPayloadPtr() + 2);

    BYTE * rgbSource = source.GetPayloadPtr() + 2 + scanlineCounts[f] * sizeof(ScanLineHeader);

    for (l = 0; l < scanlineCounts[f]; ++l) {

      // scan line length
      PINDEX width = tablePtr->length;

      // line number 
      WORD y = tablePtr->y & 0x7fff; 

      // pixel offset of scanline start
      WORD x = tablePtr->offset & 0x7fff;

      ++tablePtr;

      memcpy(rgbDest + (y * frameWidth + x) * 3, rgbSource, width * 3);

      rgbSource += width*3;
    }
  }

  // reinitialise the buffers
  Initialise();

  return TRUE;
}

#endif // OPAL_RFC4175
